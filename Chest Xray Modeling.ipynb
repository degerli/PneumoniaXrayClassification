{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Rays\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "In this notebook, I will walk through my thought process as I attempt to classify a data set of X-Ray images from patients (primarily children) with and without pneumonia through machine learning methods. The study from which the original dataset comes from can be found here: https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5.\n",
    "\n",
    "The goal is to determine, based only on these images, if the patient has viral, bacterial or no pneumonia.\n",
    "\n",
    "The authors of this paper took a different approach than I to solve this problem - utilizing transfer learning and applying pre-trained models to this data. However, as I have been practicing my skills in Pytorch, I decided it would be more useful to me if I construct and train my own model for this set.\n",
    "\n",
    "\n",
    "## Data:\n",
    "\n",
    "The data set can be viewed and downloaded through Kaggle at: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "Each file in this set is a jpeg containing an xray of an individual. Each sample either has (1) no pneumonia (2) bacterial pneumonia or (3) viral pneumonia. Here is a side by side view of a sample from each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/normal.jpeg\" width= \"200px\"/> \n",
    "      <figcaption>(1) No Pneumonia</figcaption>\n",
    "    </figure></td>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/person96_bacteria_464.jpeg\"  width= \"200px\"/>\n",
    "      <figcaption>(2) Bacterial Pneumonia</figcaption>\n",
    "    </figure> </td>\n",
    "    <td> <figure>\n",
    "        <img src=\"chestxraydemo/viral.jpeg\"  width= \"200px\"/>\n",
    "      <figcaption>(3) Viral Pneumonia</figcaption>\n",
    "    </figure> </td>\n",
    "</tr>\n",
    "</table>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"chestxraydemo/normal.jpeg\" width=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are visible differences between those who are healthy and those with pneumonia. While doctors can often diagnose pneumonia through x-rays and bloodwork, I thought it might be an interesting application of machine learning and could prove useful when doctors are not available to interpret the data. Further, distinguishing between the types of pneumonia could be especially helpful since viral and bacterial pneunomia exhibit many of the same symptoms but require different treatments.\n",
    "\n",
    "After splitting the data into different subsets for validation and testing, there are 4815 images in the training set, 482 in the validation set, and 624 in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mqOjtCvej2kv",
    "outputId": "caa312cc-4bf8-45fd-a9fe-575efc115df7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.empty_cache()\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0SSfdNTj3uA"
   },
   "outputs": [],
   "source": [
    "# Device (CPU or cuda)\n",
    "device = 'cuda'\n",
    "\n",
    "# Batch size\n",
    "bs = 64\n",
    "\n",
    "# Tensorboard Writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#Inputs\n",
    "train_path = \"D:/chest_xray/train/\"\n",
    "test_path = \"D:/chest_xray/val/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we utilize PyTorch's custom datasets to load in the data we have downloaded from Kaggle. In this process, we also apply a series of transformations to the images. They are as follows:\n",
    "\n",
    "- Firstly, we resize the images to 224x224 so that they are all of equal size. \n",
    "- Secondly, we apply random transformations of translation, rotation, horizontal flips, zoom and shear. These help to diversify our training data and enable our model to account for some of the natural differences in the dataset\n",
    "- Next, we ensure that the images have only 1 channel and convert the image to a tensor. The images were grayscale to begin with, this is just a safety net for future input.\n",
    "- Finally, we normalize the values of the image by using the mean and standard deviation of the values in the channel for the entire set. This helps to reduce training time and improve accuracy by reducing skew in our population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1U5Bq24j9jE"
   },
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "\n",
    "    # Read image files from directory and assign labels from file names\n",
    "    def __init__(self, data_root):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for infection_status in os.listdir(data_root):\n",
    "            infection_folder = os.path.join(data_root, infection_status)\n",
    "            \n",
    "            for file in os.listdir(infection_folder):\n",
    "                filepath = os.path.join(infection_folder, file)\n",
    "                self.samples.append(filepath)\n",
    "                \n",
    "                if(infection_status == 'NORMAL'):\n",
    "                    label = 0\n",
    "                elif('bacteria' in file):\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2\n",
    "                \n",
    "                self.labels.append(label)\n",
    "\n",
    "    # Image Processing\n",
    "    def transform(self, image):\n",
    "        resize = transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            transforms.RandomAffine(degrees = 4, translate=(.1,.05), shear = 0.1, scale = (0.85, 1.15)),\n",
    "            transforms.RandomHorizontalFlip(),   \n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[-0.0964],\n",
    "                     std=[0.4809])\n",
    "        ])\n",
    "        \n",
    "        return resize(image)\n",
    "    \n",
    "    # Required methods       \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.samples[idx]))\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziuVQaoaj7nq"
   },
   "outputs": [],
   "source": [
    "# Loads training data set\n",
    "def load_train_data():\n",
    "    train_data = XRayDataset(train_path)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = bs, num_workers = 0, shuffle=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUzzIHdLkANy"
   },
   "outputs": [],
   "source": [
    "# Loads testing/validation data sets\n",
    "def load_test_data():\n",
    "    data = XRayDataset(test_path)\n",
    "    test_loader = torch.utils.data.DataLoader(data, batch_size = bs, num_workers = 0, shuffle=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's a few new samples of what images look like after the transformations:\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/transformed (2).png\"  width= \"200px\"/> \n",
    "        <figcaption>No Pneumonia</figcaption>\n",
    "    </figure></td>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/transformed_1.png\"  width= \"200px\"/>\n",
    "        <figcaption>Bacterial Pneumonia</figcaption>\n",
    "    </figure> </td>\n",
    "    <td> <figure>\n",
    "        <img src=\"chestxraydemo/transformed (3).png\"  width= \"200px\"/>\n",
    "      <figcaption>Viral Pneumonia</figcaption>\n",
    "    </figure> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find mean and std of the channels in the image set\n",
    "\n",
    "# loader = load_train_data()\n",
    "# mean = 0.\n",
    "# std = 0.\n",
    "# nb_samples = 0.\n",
    "# for data,_ in loader:\n",
    "#     batch_samples = data.size(0)\n",
    "#     data = data.view(batch_samples, data.size(1), -1)\n",
    "#     mean += data.mean(2).sum(0)\n",
    "#     std += data.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean /= nb_samples\n",
    "# std /= nb_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Next, lets define our model. The process by which this model was chosen will be discussed further down in the document, however, there are a few things worth mentioning about this model.\n",
    "\n",
    "First and foremost, the final structure is derived from the AlexNet architecture (https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).\n",
    "\n",
    "It contains 5 convolutional layers with decreasing kernel size, each followed by a ReLU activation function to add some nonlinearity. Following this, we have 3 linear layers and a softmax for our final classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppcsu9UvkB1k"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()           \n",
    "            \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)        \n",
    "        self.activation = nn.RReLU(inplace = True)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        \n",
    "        self.dense1 = nn.Linear(256*6*6, 4096)\n",
    "        self.dense2 = nn.Linear(4096, 4096)\n",
    "        self.out = nn.Linear(4096, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "        ########\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "\n",
    "        x = self.dropout(x) \n",
    "        x = self.dense2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are a relatively standard way of training and testing in Pytorch. They have only been slightly modified from the PyTorch tutorials found here: https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euZk5nElkFAw"
   },
   "outputs": [],
   "source": [
    "# Adjust weights from a single epoch\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_loader = load_train_data()\n",
    "    \n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.functional.nll_loss(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_index * len(data), len(train_loader.dataset),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()))\n",
    "            niter = epoch*len(train_loader)+batch_index\n",
    "            writer.add_scalar('Train/Loss', loss.data, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCnct6YOkHn-"
   },
   "outputs": [],
   "source": [
    "# Predict and score for test set\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = load_test_data()\n",
    "    results = []\n",
    "    \n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Predict\n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            #print(pred)\n",
    "    \n",
    "    # Calculate accuracy        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # Display results\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100.0 * correct / len(test_loader.dataset)))\n",
    "    \n",
    "#     return (100.0 * correct / len(test_loader.dataset))\n",
    "    \n",
    "    # Write to tensorboard\n",
    "    writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "While the final model was derived from AlexNet, it was certainly not the first structure I tried.\n",
    "\n",
    "The initial model that I trained was an attempt to get a baseline understanding of the data and ensure that the method I was planning on taking would be feasible. As such, the model consisted of only 1 convolutional layer with a ReLU activation followed by a linear layer. Here is the figure for the validation accuracy of that model as it was trained:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/1LayerAcc.PNG\"  width= \"400px\"/> \n",
    "        <figcaption>Validation Accuracy of 1 Layer Model with Adam Optimizer</figcaption>\n",
    "    </figure></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "As the accuracy increased and our training loss decreased, it was clear that there was some learnable information in the data so I added more and more layers to the model until the improvement in accuracy was no longer worth the increase in training time. The following figure was generated by a model consisting of 3 convolutional layers and 2 linear layers. Here is the validation accuracy of that model:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/3Layer.PNG\"  width= \"400px\"/>\n",
    "        <figcaption>Validation Accuracy of 3 Layer Model with Adam Optimizer</figcaption>\n",
    "    </figure></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "As I tried adding more layers, the time in which the model took to train became too much to justify the marginal improvements in accuracy. Instead, I turned my focus to optimizing the performance of this model. In the above figures, I used an adam optimizer with a learning rate of 0.0001. The adam optimizer is perfect for getting a quick understanding of how the model performs (as long as the learning rate is reasonable) but often has a lower accuracy than stochastic gradient descent. Because of this, once I had found a structure I was happy with, I swapped over to SGD for my optimizer. Using a learning rate of 0.001 the previous model generated the following figures with SGD:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/3LayerAcc2.PNG\"  width= \"400px\"/>\n",
    "        <figcaption>Validation Accuracy of 3 Layer Model with SGD Optimizer</figcaption>\n",
    "    </figure></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "As is visible, the models are starting to perform reasonably well. However, I wanted to try a model structure that has been proven to work well for image classification yet is still not too complicated. Hence, I turned to AlexNet - consisting of 8 total layers (5 convolutional and 3 linear), the model is not extremely complicated but has a proven track record. With an adam optimizer and a learning rate of 0.0001 the model took far fewer epochs to converge. Here is the training loss and validation accuracy:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/AlexNet.PNG\"  width= \"400px\"/>\n",
    "        <figcaption>Validation Accuracy of AlexNet Model with Adam Optimizer</figcaption>\n",
    "    </figure></td>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/AlexNetLoss.PNG\"  width= \"400px\"/>\n",
    "        <figcaption>Training Loss of AlexNet Model with Adam Optimizer</figcaption>\n",
    "    </figure></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlPvFVm_oV9A",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = CNN().to(device)\n",
    "    \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "    for epoch in range(1, 1500+1):\n",
    "        train(optimizer, epoch)\n",
    "        test(epoch)\n",
    "\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), \"D:/chest_xray/model_backup/AlexNet_3_class_xray_cnn_{}.pt\".format(epoch))  \n",
    "        \n",
    "        \n",
    "    state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                     'optimizer': optimizer.state_dict(), 'scheduler' : scheduler}\n",
    "        torch.save(state, \"D:/chest_xray/model_backup/AlexNetAdamState\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"D:/chest_xray/model_backup/AlexNet_3_class_xray_cnn_746.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_path = \"D:/chest_xray/test/\"\n",
    "test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "On our test set of 624 images the AlexNet model performed reasonably well, acheiving an accuracy of 87% and producing the following confusion matrix and metrics:\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <figure>\n",
    "      <img src=\"chestxraydemo/ConfusionMatrix.PNG\"   width= \"400px\"/>\n",
    "        <figcaption>Confusion matrix of final AlexNet model</figcaption>\n",
    "    </figure></td>\n",
    "        <td> <figure>\n",
    "      <img src=\"chestxraydemo/metrics.PNG\"   width= \"400px\"/>\n",
    "        <figcaption>AlexNet Metrics</figcaption>\n",
    "    </figure></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the model is rarely wrong when predicting that a sample has pneumonia - misclassifying only 1 of this subset. An instance where this may be useful is the global shortage of testing kits for COVID-19. If a model such as this one could be applied to help diagnose patients, they would only need an xray instead (though it may just end up in xray shortages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "As this project is still ongoing, here are a few things I would like to try in the future:\n",
    "\n",
    "- Coronavirus applications\n",
    "- To increase accuracy, try more complicated models - will require more time to train\n",
    "- Try transfer learning with pretrained models\n",
    "- Wider age ranges in the data set (almost all children in this set because pneumonia is most lethal in children)\n",
    "- Add more types of pneumonia\n",
    "- Narrow data set to only include samples with pneumonia and then classify the type of pneumonia"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
